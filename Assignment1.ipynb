{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Context-sensitive spelling correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "# I used random for adding errors for test cases\n",
        "# but fixing seed did not help)\n",
        "random.seed(26)\n",
        "np.random.seed(26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract all words from the corpus\n",
        "def process_corpus(corpus_filename):\n",
        "    with open(corpus_filename) as f:\n",
        "        corpus = f.read()\n",
        "        # find words\n",
        "        lowercased_corpus = corpus.lower()\n",
        "        all_words = re.findall(r'\\w+', lowercased_corpus)\n",
        "        for w in all_words:\n",
        "            if w == 'I':\n",
        "                print('Found')\n",
        "                break\n",
        "        unique_words = set(all_words)\n",
        "    return all_words, unique_words\n",
        "\n",
        "# construct dictionary of word frequencies\n",
        "def get_words_frequencies(all_words):\n",
        "    word_freq_dict = {}\n",
        "    for word in all_words:\n",
        "        if word in word_freq_dict:\n",
        "            word_freq_dict[word] += 1\n",
        "        else:\n",
        "            word_freq_dict[word] = 1\n",
        "    return word_freq_dict\n",
        "\n",
        "# get the probability of a word\n",
        "def get_word_prob(word, all_words, word_freq_dict):\n",
        "    # check that the word exists in the vocabulary\n",
        "    if word in word_freq_dict:\n",
        "        return word_freq_dict[word] / len(all_words)\n",
        "    \n",
        "    return 0\n",
        "\n",
        "# function to generate words from the given one by adding 1 character\n",
        "def add_char(word):\n",
        "    words_with_char_added = []\n",
        "    possible_chars = 'qwertyuiopasdfghjklzxcvbnm'\n",
        "    for i in range(len(word)):\n",
        "        for char in possible_chars:\n",
        "            words_with_char_added.append(word[:i] + char + word[i:])\n",
        "        words_with_char_added.append(word + char)\n",
        "    return words_with_char_added\n",
        "\n",
        "# function to generate words from the given one by deleting 1 character\n",
        "def delete_char(word):\n",
        "    words_with_char_deleted = []\n",
        "    for i in range(len(word)):\n",
        "        words_with_char_deleted.append(word[:i] + word[i+1:])\n",
        "    return words_with_char_deleted\n",
        "\n",
        "# function to generate words from the given one by replacing 1 character\n",
        "def replace_char(word):\n",
        "    words_with_char_replaced = []\n",
        "    possible_chars = 'qwertyuiopasdfghjklzxcvbnm'\n",
        "    for i in range(len(word)):\n",
        "        for char in possible_chars:\n",
        "            new_word = word[:i] + char + word[i+1:]\n",
        "            words_with_char_replaced.append(new_word)\n",
        "    return words_with_char_replaced\n",
        "\n",
        "# function to generate words from the given one by swapping 2 characters\n",
        "def swap_chars(word):\n",
        "    words_with_chars_swapped = []\n",
        "    for i in range(len(word)-1):\n",
        "        new_word = word[:i] + word[i+1] + word[i] + word[i+2:]\n",
        "        words_with_chars_swapped.append(new_word)\n",
        "    return words_with_chars_swapped\n",
        "\n",
        "# filter only words that are present in the vocabulary\n",
        "def filter_existent_words(words, vocabulary):\n",
        "    return [word for word in words if word in vocabulary]\n",
        "\n",
        "# check the word presence in the vocabulary\n",
        "def check_existence(word, vocabulary):\n",
        "    if word in vocabulary:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "# function for generating words obtained by adding, deleting, \n",
        "# replacing or swapping 1 character\n",
        "def generate_candidates_edit_1(word):\n",
        "    candidates = []\n",
        "    words_with_char_added = add_char(word)\n",
        "    words_with_char_deleted = delete_char(word)\n",
        "    words_with_char_replaced = replace_char(word)\n",
        "    words_with_chars_swapped = swap_chars(word)\n",
        "\n",
        "    candidates.extend(words_with_char_added)\n",
        "    candidates.extend(words_with_char_deleted)\n",
        "    candidates.extend(words_with_char_replaced)\n",
        "    candidates.extend(words_with_chars_swapped)\n",
        "    unique_candidate_words = set(candidates)\n",
        "    \n",
        "    return unique_candidate_words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Norwig's solution (Unigram model)\n",
        "\n",
        "The main idea of this model is to generate words that are similar to the given one and choose the best one based on the frequency of it in the corpus.\n",
        "\n",
        "This model was chosen for the first implementaton because of its simplicity. Nevertheless, it does not capture the context and its usage is reasonable for correction of single words.\n",
        "\n",
        "As the example of the model implementation I used the [Norwig's solution](https://norvig.com/spell-correct.html) and [video tutorial](https://www.youtube.com/watch?v=4yOKlWZk52M).\n",
        "\n",
        "To compare my model implementation with the official Norwig's model as a corpus I decided to use `big.txt` dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of words in corpus: 1115585\n",
            "Num of unique words in corpus: 32198\n"
          ]
        }
      ],
      "source": [
        "all_words, unique_words = process_corpus('big.txt')\n",
        "print(f\"Num of words in corpus: {len(all_words)}\")\n",
        "print(f\"Num of unique words in corpus: {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_freq = get_words_frequencies(all_words)\n",
        "word_freq['cat']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to correct single word\n",
        "def correct_word_simple(word, vocabulary):\n",
        "    word = word.lower()\n",
        "    if check_existence(word, vocabulary):\n",
        "        return word\n",
        "    unique_candidates_edit_1 = generate_candidates_edit_1(word)\n",
        "    candidates_edit_2 = []\n",
        "    for candidate in unique_candidates_edit_1:\n",
        "        new_cadidates_edit_2 = generate_candidates_edit_1(candidate)\n",
        "        candidates_edit_2.extend(new_cadidates_edit_2)\n",
        "    \n",
        "    unique_candidates_edit_2 = set(candidates_edit_2)\n",
        "\n",
        "    all_candidates = []\n",
        "    unique_candidates_edit_1_existent = filter_existent_words(unique_candidates_edit_1, vocabulary)\n",
        "    unique_candidates_edit_2_existent = filter_existent_words(unique_candidates_edit_2, vocabulary)\n",
        "    for candidate in unique_candidates_edit_1_existent:\n",
        "        all_candidates.append((candidate, 1))\n",
        "    for candidate in unique_candidates_edit_2_existent:\n",
        "        all_candidates.append((candidate, 2))\n",
        "    unique_candidates = set(all_candidates)\n",
        "\n",
        "    # sort unique_candidates by the distance and the probability of the word\n",
        "    sorted_candidates = sorted(unique_candidates, key=lambda x: (x[1], -get_word_prob(x[0], all_words, word_freq)))\n",
        "    if len(sorted_candidates) > 0:\n",
        "        best_candidate = sorted_candidates[0]\n",
        "    else:\n",
        "        best_candidate = (word, 0)\n",
        "\n",
        "    return best_candidate[0]\n",
        "\n",
        "# function to correct the text using Norwig's idea\n",
        "def correct_text(given_text):\n",
        "    found_words = re.finditer(r'\\b\\w+\\b', given_text)\n",
        "    cur_idx = 0\n",
        "    corrected_text = []\n",
        "    for cur_word_with_boundaries in found_words:\n",
        "        word = cur_word_with_boundaries.group()\n",
        "        start_idx, end_idx = cur_word_with_boundaries.span()\n",
        "        corrected_word = correct_word_simple(word, unique_words)\n",
        "        # to save the spaces and punctuation\n",
        "        corrected_text.append(given_text[cur_idx:start_idx])\n",
        "        # if the word's characters are all UPPER\n",
        "        if word.isupper():\n",
        "            corrected_word = corrected_word.upper()\n",
        "        # if the first letter is in upper case\n",
        "        elif word.istitle():\n",
        "            corrected_word = corrected_word.capitalize()\n",
        "    \n",
        "        corrected_text.append(corrected_word)\n",
        "        cur_idx = end_idx\n",
        "    corrected_text.append(given_text[cur_idx:])\n",
        "    corrected_text_result = ''.join(corrected_text)\n",
        "        \n",
        "    return corrected_text_result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examples of the model outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'spelling'"
            ]
          },
          "execution_count": 304,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_word_simple('speling', unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am a student!\n"
          ]
        }
      ],
      "source": [
        "corrected_text = correct_text(\"I am a student7!\")\n",
        "print(corrected_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It is spelling correction task.\n"
          ]
        }
      ],
      "source": [
        "text = 'It is speling correction task.'\n",
        "corrected_text = correct_text(text)\n",
        "print(corrected_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "king sport\n"
          ]
        }
      ],
      "source": [
        "text_example = 'dking sport'\n",
        "corrected_example = correct_text(text_example)\n",
        "print(corrected_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "king species\n"
          ]
        }
      ],
      "source": [
        "text_example2 = 'dking species'\n",
        "corrected_example2 = correct_text(text_example2)\n",
        "print(corrected_example2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability of the word 'king': 0.00021334098253382753, frequency: 238\n",
            "Probability of the word 'doing': 0.00015955754155891303, frequency: 178\n",
            "Probability of the word 'dying': 7.171125463321934e-05, frequency: 80\n"
          ]
        }
      ],
      "source": [
        "prob_king = get_word_prob('king', all_words, word_freq)\n",
        "prob_doing = get_word_prob('doing', all_words, word_freq)\n",
        "prob_dying = get_word_prob('dying', all_words, word_freq)\n",
        "print(f\"Probability of the word 'king': {prob_king}, frequency: {word_freq['king']}\")\n",
        "print(f\"Probability of the word 'doing': {prob_doing}, frequency: {word_freq['doing']}\")\n",
        "print(f\"Probability of the word 'dying': {prob_dying}, frequency: {word_freq['dying']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above cell output we can see that since the word `king`occurs more often in the training corpus, then the model tends to choose it instead of words `doind` and `dying` that are more suitable in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bigram model\n",
        "\n",
        "The main idea of the bigram model is to choose the most appropriate word not just by the frequency of its occurance in the corpus but by the frequency of occurance of the current word together with the previous one. This distinction giveas the opportunity to understand the context and avoid the problem of choosing the most frequent word from the generated candidates.\n",
        "\n",
        "As a training corpus I decided to choose the datasets `count_1w.txt` (for single word frequencies) and `count_2w.txt` (for bigram frequencies). I found them in the [website](http://norvig.com/ngrams/).\n",
        "\n",
        "Firstly, I implemented simple probability calculation. After that I decided to add Laplase smoothing to avoid 0 probability for unseen bigrams as was stated in the [article](https://web.stanford.edu/~jurafsky/slp3/3.pdf) about N-gram language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get single word frequencies\n",
        "def process_1_word_freq(filename):\n",
        "    with open(filename) as f:\n",
        "        word_freq = {}\n",
        "        for line in f:\n",
        "            word, freq = line.strip().split()\n",
        "            word = word.lower()\n",
        "            word_freq[word] = int(freq)\n",
        "    return word_freq\n",
        "\n",
        "# get bigrams frequencies\n",
        "def process_2_word_freq(filename):\n",
        "    with open(filename) as f:\n",
        "        word_freq = {}\n",
        "        for line in f:\n",
        "            word1, word2, freq = line.strip().split()\n",
        "            word1 = word1.lower()\n",
        "            word2 = word2.lower()\n",
        "            bigram = word1 + ' ' + word2\n",
        "            word_freq[bigram] = int(freq)\n",
        "    return word_freq\n",
        "\n",
        "# without Laplase smoothing\n",
        "def calculate_bigram_prob(prev_word, cur_word, bigram_freq, single_word_freq):\n",
        "    lowered_prev_word = prev_word.lower()\n",
        "    lowered_cur_word = cur_word.lower()\n",
        "    bigram = lowered_prev_word + ' ' + lowered_cur_word\n",
        "    total_single_word_freq = sum(single_word_freq.values())\n",
        "    if bigram in bigram_freq:\n",
        "        if lowered_prev_word in single_word_freq:\n",
        "            return bigram_freq[bigram] / single_word_freq[lowered_prev_word]\n",
        "        else:\n",
        "            return bigram_freq[bigram] / total_single_word_freq\n",
        "    else:\n",
        "        if lowered_cur_word in single_word_freq:\n",
        "            return single_word_freq[lowered_cur_word] / total_single_word_freq\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "# adding Laplase smoothing\n",
        "def calculate_bigram_prob_with_laplase_smoothing(prev_word, cur_word, bigram_freq, single_word_freq):\n",
        "    lowered_prev_word = prev_word.lower()\n",
        "    lowered_cur_word = cur_word.lower()\n",
        "    bigram = lowered_prev_word + ' ' + lowered_cur_word\n",
        "    bigram_count = bigram_freq.get(bigram, 0)\n",
        "    prev_word_count = single_word_freq.get(lowered_prev_word, 0)\n",
        "    smoothed_prob = (bigram_count + 1)/ (prev_word_count + len(unique_words))\n",
        "    return smoothed_prob\n",
        "\n",
        "# function to calculate the probability of the word sequence based on the bigram probabilities\n",
        "def calculate_word_sequence_prob(words, bigram_freq, single_word_freq, prev_token = '<S>', edit_distance=1):\n",
        "    result = 0\n",
        "    for i in range(len(words)):\n",
        "        if i==0:\n",
        "            prob = calculate_bigram_prob(prev_token, words[i], bigram_freq, single_word_freq)\n",
        "        else:\n",
        "            prob = calculate_bigram_prob(words[i-1], words[i], bigram_freq, single_word_freq)\n",
        "        if prob == 0:\n",
        "            prob = 1e-10\n",
        "        result+= np.log(prob)\n",
        "        \n",
        "        # penalize for number of corrections\n",
        "        result = result - 0.05*edit_distance\n",
        "        # print(result)\n",
        "    return result\n",
        "\n",
        "def calculate_word_sequence_prob_with_laplase_smoothing(words, bigram_freq, single_word_freq, prev_token = '<S>', edit_distance=1):\n",
        "    result = 0\n",
        "    for i in range(len(words)):\n",
        "        if i==0:\n",
        "            prob = calculate_bigram_prob_with_laplase_smoothing(prev_token, words[i], bigram_freq, single_word_freq)\n",
        "        else:\n",
        "            prob = calculate_bigram_prob_with_laplase_smoothing(words[i-1], words[i], bigram_freq, single_word_freq)\n",
        "        if prob == 0:\n",
        "            prob = 1e-10\n",
        "        result+= np.log(prob)\n",
        "        \n",
        "        # penalize for number of corrections\n",
        "        result = result - 0.05*edit_distance\n",
        "        # print(result)\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [],
      "source": [
        "single_word_freq = process_1_word_freq('count_1w.txt')\n",
        "bigram_freq = process_2_word_freq('count_2w.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7.259827996986489e-05\n"
          ]
        }
      ],
      "source": [
        "prob = calculate_bigram_prob('the', 'cat', bigram_freq, single_word_freq)\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.079682723190858e-06\n"
          ]
        }
      ],
      "source": [
        "prob = calculate_bigram_prob('t', 'cot', bigram_freq, single_word_freq)\n",
        "print(prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-17.360431386064402\n"
          ]
        }
      ],
      "source": [
        "word_seq_prob = calculate_word_sequence_prob(['the', 'cat'], bigram_freq, single_word_freq)\n",
        "print(word_seq_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-22.226910528077223\n"
          ]
        }
      ],
      "source": [
        "word_seq_prob = calculate_word_sequence_prob(['t', 'cot'], bigram_freq, single_word_freq)\n",
        "print(word_seq_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correct_word_bigram(given_word, given_text_tokens, given_word_idx):\n",
        "    given_word_lower = given_word.lower()\n",
        "    \n",
        "    # if the word is correct, then do not generate candidates\n",
        "    if check_existence(given_word_lower, unique_words):\n",
        "        return given_word\n",
        "\n",
        "    # generate edit 1 distance candidates\n",
        "    all_candidates_with_edit_dist = []\n",
        "    unique_candidates_edit_1 = generate_candidates_edit_1(given_word_lower)\n",
        "    unique_candidates_edit_1_existent = filter_existent_words(unique_candidates_edit_1, unique_words)\n",
        "\n",
        "    for candidate in unique_candidates_edit_1_existent:\n",
        "        all_candidates_with_edit_dist.append((candidate, 1))\n",
        "    \n",
        "    # generate edit 2 distance candidates\n",
        "    candidates_edit_2 = []\n",
        "    for candidate in unique_candidates_edit_1:\n",
        "        new_candidates_edit_2 = generate_candidates_edit_1(candidate)\n",
        "        candidates_edit_2.extend(new_candidates_edit_2)\n",
        "    \n",
        "    unique_candidates_edit_2_existent = filter_existent_words(set(candidates_edit_2), unique_words)\n",
        "    for candidate in unique_candidates_edit_2_existent:\n",
        "        all_candidates_with_edit_dist.append((candidate, 2))\n",
        "    \n",
        "    all_unique_candidates_with_edit_dist = set(all_candidates_with_edit_dist)\n",
        "\n",
        "    # if there are no candidates that are present in the vocabulary, return the original word\n",
        "    if not all_unique_candidates_with_edit_dist:\n",
        "        return given_word \n",
        "    \n",
        "\n",
        "    # for each candidate calculate the probability of the word sequence with this candidate\n",
        "    # and select one with the larger probability\n",
        "    new_probabilities = []\n",
        "    for (candidate, edit_dist) in all_unique_candidates_with_edit_dist:\n",
        "        new_word_sequence = given_text_tokens.copy()\n",
        "        new_word_sequence[given_word_idx] = candidate\n",
        "        prob = calculate_word_sequence_prob(new_word_sequence, bigram_freq, single_word_freq, edit_distance=edit_dist)\n",
        "        new_probabilities.append(prob)\n",
        "    best_candidate = list(all_unique_candidates_with_edit_dist)[new_probabilities.index(max(new_probabilities))][0]\n",
        "\n",
        "    # save word in the given format\n",
        "    if given_word.isupper():\n",
        "        return best_candidate.upper()\n",
        "    elif given_word.istitle():\n",
        "        return best_candidate.capitalize()\n",
        "    else:\n",
        "        return best_candidate\n",
        "    \n",
        "def correct_word_bigram_with_laplase_smoothing(given_word, given_text_tokens, given_word_idx):\n",
        "    given_word_lower = given_word.lower()\n",
        "    \n",
        "    # if the word is correct, then do not generate candidates\n",
        "    if check_existence(given_word_lower, unique_words):\n",
        "        return given_word\n",
        "\n",
        "    # generate edit 1 distance candidates\n",
        "    all_candidates_with_edit_dist = []\n",
        "    unique_candidates_edit_1 = generate_candidates_edit_1(given_word_lower)\n",
        "    unique_candidates_edit_1_existent = filter_existent_words(unique_candidates_edit_1, unique_words)\n",
        "\n",
        "    for candidate in unique_candidates_edit_1_existent:\n",
        "        all_candidates_with_edit_dist.append((candidate, 1))\n",
        "    \n",
        "    # generate edit 2 distance candidates\n",
        "    candidates_edit_2 = []\n",
        "    for candidate in unique_candidates_edit_1:\n",
        "        new_candidates_edit_2 = generate_candidates_edit_1(candidate)\n",
        "        candidates_edit_2.extend(new_candidates_edit_2)\n",
        "    \n",
        "    unique_candidates_edit_2_existent = filter_existent_words(set(candidates_edit_2), unique_words)\n",
        "    for candidate in unique_candidates_edit_2_existent:\n",
        "        all_candidates_with_edit_dist.append((candidate, 2))\n",
        "    \n",
        "    all_unique_candidates_with_edit_dist = set(all_candidates_with_edit_dist)\n",
        "\n",
        "    # if there are no candidates that are present in the vocabulary, return the original word\n",
        "    if not all_unique_candidates_with_edit_dist:\n",
        "        return given_word \n",
        "    \n",
        "\n",
        "    # for each candidate calculate the probability of the word sequence with this candidate\n",
        "    # and select one with the larger probability\n",
        "    new_probabilities = []\n",
        "    for (candidate, edit_dist) in all_unique_candidates_with_edit_dist:\n",
        "        new_word_sequence = given_text_tokens.copy()\n",
        "        new_word_sequence[given_word_idx] = candidate\n",
        "        prob = calculate_word_sequence_prob_with_laplase_smoothing(new_word_sequence, bigram_freq, single_word_freq, edit_distance=edit_dist)\n",
        "        new_probabilities.append(prob)\n",
        "    best_candidate = list(all_unique_candidates_with_edit_dist)[new_probabilities.index(max(new_probabilities))][0]\n",
        "\n",
        "    # save word in the given format\n",
        "    if given_word.isupper():\n",
        "        return best_candidate.upper()\n",
        "    elif given_word.istitle():\n",
        "        return best_candidate.capitalize()\n",
        "    else:\n",
        "        return best_candidate\n",
        "\n",
        "def correct_text_bigram(given_text):\n",
        "    found_words = list(re.finditer(r'\\b\\w+\\b', given_text))\n",
        "    corrected_text = []\n",
        "    cur_idx = 0\n",
        "\n",
        "    for idx, match in enumerate(found_words):\n",
        "        word = match.group()\n",
        "        start, end = match.span()\n",
        "\n",
        "        # save the text before the word because of spaces and punctuation to reconstruct the initial text\n",
        "        corrected_text.append(given_text[cur_idx:start])\n",
        "        corrected_word = correct_word_bigram(word, [m.group() for m in found_words], idx)\n",
        "        corrected_text.append(corrected_word)\n",
        "        cur_idx = end\n",
        "\n",
        "    # save the text after the last word because of spaces and punctuation\n",
        "    corrected_text.append(given_text[cur_idx:])\n",
        "    return \"\".join(corrected_text)\n",
        "\n",
        "def correct_text_bigram_with_laplase_smoothing(given_text):\n",
        "    found_words = list(re.finditer(r'\\b\\w+\\b', given_text))\n",
        "    corrected_text = []\n",
        "    cur_idx = 0\n",
        "\n",
        "    for idx, match in enumerate(found_words):\n",
        "        word = match.group()\n",
        "        start, end = match.span()\n",
        "\n",
        "        # save the text before the word because of spaces and punctuation to reconstruct the initial text\n",
        "        corrected_text.append(given_text[cur_idx:start])\n",
        "        corrected_word = correct_word_bigram_with_laplase_smoothing(word, [m.group() for m in found_words], idx)\n",
        "        corrected_text.append(corrected_word)\n",
        "        cur_idx = end\n",
        "\n",
        "    # save the text after the last word because of spaces and punctuation\n",
        "    corrected_text.append(given_text[cur_idx:])\n",
        "    return \"\".join(corrected_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examples of bigram model outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! I am a student.'"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram('Hello! I am a student7.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'diving sport'"
            ]
          },
          "execution_count": 319,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram('dking sport')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'diving species'"
            ]
          },
          "execution_count": 320,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram('dking species')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examples of bigram model with Laplase smoothing outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! I am a student.'"
            ]
          },
          "execution_count": 342,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram_with_laplase_smoothing('Hello! I am a student7.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ing sport'"
            ]
          },
          "execution_count": 321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram_with_laplase_smoothing('dking sport')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ing species'"
            ]
          },
          "execution_count": 322,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "correct_text_bigram_with_laplase_smoothing('dking species')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Candidates for 'dking': {'dkinyg', 'dving', 'doing', 'uking', 'dkaing', 'dkwing', 'dkidg', 'sking', 'daking', 'dkiny', 'dtking', 'dkinvg', 'dkifg', 'dkinz', 'dkitng', 'dkong', 'dkingg', 'hking', 'dkixng', 'djking', 'xking', 'dkivng', 'dkilng', 'dning', 'dkiung', 'dkinx', 'dling', 'dying', 'dkinc', 'dkiyng', 'dkeing', 'dkixg', 'dkijng', 'dkicg', 'bdking', 'dkinl', 'dkxing', 'dfing', 'dkibng', 'dkieg', 'dkinw', 'gdking', 'dkiqng', 'bking', 'dkipg', 'dkiang', 'dkcng', 'kking', 'mdking', 'dcking', 'dikng', 'diing', 'dkinig', 'fking', 'dkpng', 'dqking', 'wking', 'zking', 'dkina', 'dkind', 'dcing', 'dvking', 'dkinpg', 'edking', 'ldking', 'yking', 'dkinsg', 'dkigng', 'dkine', 'dkning', 'dfking', 'dgking', 'dkinjg', 'dkang', 'dkisng', 'dkinag', 'dkiag', 'dkyng', 'dwing', 'dging', 'dkfng', 'fdking', 'dkindg', 'rdking', 'dkinb', 'cdking', 'dkizg', 'dknng', 'idking', 'dkink', 'dkding', 'dkilg', 'xdking', 'dkting', 'dxking', 'dkqing', 'dkino', 'dkping', 'duking', 'dsing', 'dbing', 'dkinkg', 'dkrng', 'hdking', 'dkineg', 'dkiog', 'dkibg', 'dkinlg', 'dkidng', 'pking', 'dkming', 'dkinmg', 'dkwng', 'dkikg', 'dkinn', 'ddking', 'dkikng', 'dkinug', 'dkeng', 'dkiqg', 'dkiwng', 'odking', 'dkvng', 'jdking', 'nking', 'dbking', 'qking', 'dkhng', 'dming', 'dmking', 'dkzng', 'dkbing', 'dkiing', 'dkung', 'dknig', 'dkoing', 'dkizng', 'dkimg', 'dkjing', 'deking', 'dping', 'dkgng', 'adking', 'wdking', 'dkin', 'zdking', 'dkinog', 'duing', 'dting', 'deing', 'dkkng', 'dkinbg', 'qdking', 'rking', 'dkbng', 'dkinf', 'dkinng', 'dkking', 'dkmng', 'gking', 'drking', 'dkving', 'aking', 'dzing', 'dpking', 'daing', 'dkqng', 'pdking', 'ndking', 'udking', 'dwking', 'dkinwg', 'dkinfg', 'eking', 'vking', 'dqing', 'dxing', 'dking', 'dkinr', 'dkling', 'dkincg', 'dkhing', 'dkxng', 'dring', 'kdking', 'dkying', 'dhing', 'dkinh', 'dkifng', 'dkimng', 'dkint', 'dkieng', 'dkiyg', 'doking', 'dkinrg', 'dkinxg', 'dklng', 'dkijg', 'sdking', 'dkivg', 'dkiig', 'dksng', 'vdking', 'mking', 'diking', 'dkihng', 'dkini', 'dsking', 'dding', 'dkicng', 'ydking', 'dhking', 'dkig', 'dkirg', 'dkdng', 'dkinp', 'kding', 'dzking', 'dkng', 'dlking', 'dyking', 'dkintg', 'dnking', 'dkigg', 'dkcing', 'dkiong', 'dkiug', 'dkins', 'dkjng', 'dksing', 'dkging', 'iking', 'dkring', 'dkinu', 'dktng', 'dkinv', 'dkingm', 'oking', 'dkinq', 'dkihg', 'lking', 'ding', 'dkzing', 'dkfing', 'dkinm', 'dkinhg', 'dkinqg', 'dkign', 'dkipng', 'cking', 'tking', 'djing', 'dkirng', 'dkisg', 'dkuing', 'dkiwg', 'dkitg', 'tdking', 'jking', 'dkinj', 'dkinzg', 'king'}\n"
          ]
        }
      ],
      "source": [
        "word='dking'\n",
        "candidates = generate_candidates_edit_1(word)\n",
        "print(f\"Candidates for '{word}': {candidates}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigram count: 0\n",
            "Bigram count: 0\n",
            "Single word count for dying: 9123557\n",
            "Single word count for doing: 80821946\n"
          ]
        }
      ],
      "source": [
        "print(\"Bigram count for doing sport:\", bigram_freq.get(\"doing sport\", 0))\n",
        "print(\"Bigram count for dying species:\", bigram_freq.get(\"dying species\", 0))\n",
        "print(\"Single word count for dying:\", single_word_freq.get(\"dying\", 0))\n",
        "print(\"Single word count for doing:\", single_word_freq.get(\"doing\", 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Single word count for ing: 17637606\n"
          ]
        }
      ],
      "source": [
        "print(\"Single word count for ing:\", single_word_freq.get(\"ing\", 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the datasets used for training language modela there were no bigrams for `doing sport` and no bigrams for `dying species`. Therefore, for the test case `dking sport` and `dking species` the model gives not expected results: `diving sport` and `diving species`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Decisions justification\n",
        "\n",
        "### Datasets\n",
        "\n",
        "**Training corpus**\n",
        "\n",
        "I used the datasets from the [website](http://norvig.com/ngrams/) because this makes it possible to compare the results of Norvig's original model and my implementation, since the results of such models depend on the corpus on which they were trained.\n",
        "\n",
        "In the article about N-gram models there was an idea about back-off: to backtrack to N-1 gram if there is no N-gram in the dataset and calculate the probability of this N-gram through a linear combination of probabilities from the unigram to the N-gram. I wanted to implement trigram model but I did not find the appropriate dataset. For this reason I tried to extract unigrams, bigrams and trigrams from the nltk corpuses (brown) and train the language model on it. However, this does not solve the problem with `dking sport` and `dking species` correction and I kept the models trained on datasets close to the official implementation to be able to compare. \n",
        "\n",
        "**Test datasets**\n",
        "\n",
        "I tested the model on 5 test cases. \n",
        "\n",
        "2 of them (words from unit test and from the `spell-testset1.txt`) were mentioned in the official solution. I took them to compare the results. \n",
        "\n",
        "The other 3 includes:\n",
        "- sentence generated from the bigram corpus `count_2w.txt` with randomly generated spelling mistakes (to test model in the conditions similarto training)\n",
        "- paragraph generated from the bigram corpus `count_2w.txt` with randomly generated spelling mistakes (to test model in the conditions similarto training)\n",
        "- text fragment from the book \"The Lord of The Rings\" by John Ronald Reuel Tolkien (difficult test case for the model because there are a lot of unseen words)\n",
        "\n",
        "### Weights for edit1 and edit2 distances\n",
        "\n",
        "I decided to penalize the candidates by reducing their probability by `0.05*edit_distance`. The number `0.05` was chosen by experiments and worked well. Edit1 word will be selected with higher probability than the edit2 candidate in case of similar probabilities.\n",
        "\n",
        "\n",
        "### Absent word probabilities\n",
        "\n",
        "To avoid problem with the similarly small probabilities for unseen words or bigrams I slightly modified the probability calculation for the simple bigram model by considering different cases. Moreover, I added Laplase smoothing that worked better.\n",
        "\n",
        "### Metric for evaluation\n",
        "\n",
        "To evaluate the models I have chosen corrected word accuracy metric. It is calculated as (the number of correctly corrected words)/(the number of words with errors that are present in the dataset). In my opinion this metric is honest because we cannot evaluate the model on the words that were not present in the corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Difficulties\n",
        "\n",
        "1. **Probability calculation**\n",
        "\n",
        "Multiplication of probabilities fastly becomes 0 => use sum of logarithms of probabilities instead of raw probability multiplication.\n",
        "\n",
        "2. **Capturing context** - moving from unigrams to bigrams\n",
        "\n",
        "With unigrams for phrases of 2 words the context is not captured. Therefore, I decided to use bigram models.\n",
        "\n",
        "3. **Corpus**\n",
        "\n",
        "- large size of the file with huge corpus\n",
        "\n",
        "To get better results the model should process a large corpus.After trying to use a large dataset, my computer got sick and I decided to postpone this idea and think about other ways to improve the result. For example, calculating the probability of bigram in the case of its absence in the training corpus 😅\n",
        "\n",
        "- no appropriate trigram dataset\n",
        "\n",
        "Since I had no success in finding an open suitable dataset with trigrams, I tried to train the model on the brown corpus from nltk, but it did not help to improve the result significantly. Therefore, for the convenience of comparing my results with the official solution of Norvig, I decided to leave the datasets given on his website.\n",
        "\n",
        "4. **Probabilities for unseen words**\n",
        "\n",
        "The approach with the usual calculation of probabilities for both unigrams and bigrams is not very suitable, because for words or bigrams that the model sees for the first time the probability will be 0. Therefore, to calculate the probability in the usual bigram, I considered the possible options and for each of them suggested how the probability could be calculated to avoid zero probabilities. In addition, I tried to use Laplase smoothing, which showed good results, even though the authors of the paper highlighted that it was not the best idea, but it works.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluation on a test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comparing my unigram model with Norwig's\n",
        "\n",
        "I noticed slight difference in the training corpus because the size of the vocabulary in my case is 32198 and in Norwig's solution is 32192. I suppose that the file `big.txt` could have been changed a bit. But values like word count don't differ much, so I just removed the check for equality of such values to the Norvig corpus values from the unit tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32198"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Norvig has 32192\n",
        "len(unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1115585"
            ]
          },
          "execution_count": 327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Norvig has 1115504\n",
        "len(all_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "79809"
            ]
          },
          "execution_count": 328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Norvig has 79808\n",
        "word_freq['the']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_prob('quintessential', all_words, word_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.07154004401278254"
            ]
          },
          "execution_count": 330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_word_prob('the', all_words, word_freq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Norvig tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [],
      "source": [
        "# Norvig tests\n",
        "def unit_tests():\n",
        "    assert correct_text('speling') == 'spelling'              # insert\n",
        "    assert correct_text('korrectud') == 'corrected'           # replace 2\n",
        "    assert correct_text('bycycle') == 'bicycle'               # replace\n",
        "    assert correct_text('inconvient') == 'inconvenient'       # insert 2\n",
        "    assert correct_text('arrainged') == 'arranged'            # delete\n",
        "    assert correct_text('peotry') =='poetry'                  # transpose\n",
        "    assert correct_text('peotryy') =='poetry'                 # transpose + delete\n",
        "    assert correct_text('word') == 'word'                     # known\n",
        "    assert correct_text('quintessential') == 'quintessential' # unknown\n",
        "    assert get_word_prob('quintessential', all_words, word_freq) == 0\n",
        "    assert 0.07 < get_word_prob('the', all_words, word_freq) < 0.08\n",
        "    return 'unit_tests pass'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For unigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unit_tests pass\n",
            "correction(contende) => contend (3); expected contented (13)\n",
            "correction(contended) => contended (9); expected contented (13)\n",
            "correction(proplen) => people (891); expected problem (71)\n",
            "correction(guic) => guns (111); expected juice (5)\n",
            "correction(juce) => june (44); expected juice (5)\n",
            "correction(jucie) => julie (71); expected juice (5)\n",
            "correction(juise) => guise (8); expected juice (5)\n",
            "correction(juse) => just (767); expected juice (5)\n",
            "correction(localy) => local (181); expected locally (10)\n",
            "correction(compair) => company (190); expected compare (29)\n",
            "correction(transportibility) => transportibility (0); expected transportability (0)\n",
            "correction(miniscule) => miniscule (0); expected minuscule (0)\n",
            "correction(poartry) => party (298); expected poetry (10)\n",
            "correction(stanerdizing) => stanerdizing (0); expected standardizing (0)\n",
            "correction(futher) => father (533); expected further (138)\n",
            "correction(biscutes) => disputes (27); expected biscuits (8)\n",
            "correction(receit) => recent (53); expected receipt (13)\n",
            "correction(receite) => receive (95); expected receipt (13)\n",
            "correction(reciet) => recite (4); expected receipt (13)\n",
            "correction(remined) => remained (231); expected remind (9)\n",
            "correction(annt) => anna (294); expected aunt (52)\n",
            "correction(ther) => the (79809); expected there (2972)\n",
            "correction(totaly) => total (35); expected totally (9)\n",
            "correction(vistid) => viscid (3); expected visited (28)\n",
            "correction(ment) => men (1145); expected meant (113)\n",
            "correction(sorces) => forces (176); expected sources (30)\n",
            "correction(desicate) => delicate (54); expected desiccate (0)\n",
            "correction(dessicate) => delicate (54); expected desiccate (0)\n",
            "correction(dessiccate) => dessiccate (0); expected desiccate (0)\n",
            "correction(splened) => opened (216); expected splendid (77)\n",
            "correction(acount) => count (748); expected account (177)\n",
            "correction(semetary) => secretary (52); expected cemetery (2)\n",
            "correction(lates) => later (334); expected latest (17)\n",
            "correction(rember) => member (50); expected remember (161)\n",
            "correction(cak) => can (1095); expected cake (6)\n",
            "correction(chosing) => closing (35); expected choosing (20)\n",
            "correction(rote) => rose (243); expected wrote (149)\n",
            "correction(awfall) => wall (189); expected awful (29)\n",
            "correction(lauf) => last (565); expected laugh (70)\n",
            "correction(laught) => caught (90); expected laugh (70)\n",
            "correction(diagrammaticaally) => diagrammaticaally (0); expected diagrammatically (0)\n",
            "correction(pomes) => comes (91); expected poems (3)\n",
            "correction(perple) => people (891); expected purple (29)\n",
            "correction(perpul) => peril (7); expected purple (29)\n",
            "correction(hierachial) => hierachial (0); expected hierarchal (0)\n",
            "correction(wonted) => wonted (1); expected wanted (213)\n",
            "correction(planed) => planed (1); expected planned (15)\n",
            "correction(muinets) => muskets (22); expected minutes (146)\n",
            "correction(aranging) => arranging (19); expected arrangeing (0)\n",
            "correction(accesing) => acceding (1); expected accessing (0)\n",
            "correction(stomec) => some (1536); expected stomach (42)\n",
            "correction(embaras) => embargo (7); expected embarrass (0)\n",
            "correction(embarass) => embarass (0); expected embarrass (0)\n",
            "correction(auxillary) => axillary (31); expected auxiliary (0)\n",
            "correction(failes) => failed (63); expected fails (20)\n",
            "correction(poame) => some (1536); expected poem (6)\n",
            "correction(liew) => view (179); expected lieu (7)\n",
            "correction(lones) => bones (257); expected loans (13)\n",
            "correction(addresable) => addresable (0); expected addressable (0)\n",
            "correction(centraly) => central (72); expected centrally (0)\n",
            "correction(choise) => choose (54); expected choice (46)\n",
            "correction(oppisit) => oppisit (0); expected opposite (80)\n",
            "correction(cartains) => captains (12); expected curtains (5)\n",
            "correction(certans) => certains (1); expected curtains (5)\n",
            "correction(courtens) => countess (497); expected curtains (5)\n",
            "correction(curtions) => portions (56); expected curtains (5)\n",
            "correction(adress) => dress (138); expected address (76)\n",
            "correction(adres) => acres (36); expected address (76)\n",
            "correction(superceed) => superseded (9); expected supersede (1)\n",
            "74% of 270 correct (6% unknown) at 19 words per second \n"
          ]
        }
      ],
      "source": [
        "def spelltest(tests, verbose=True):\n",
        "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
        "    import time\n",
        "    start = time.time()\n",
        "    good, unknown = 0, 0\n",
        "    n = len(tests)\n",
        "    for right, wrong in tests:\n",
        "        w = correct_word_simple(wrong, unique_words)\n",
        "        good += (w == right)\n",
        "        if w != right:\n",
        "            unknown += (right not in unique_words)\n",
        "            if verbose:\n",
        "                print('correction({}) => {} ({}); expected {} ({})'\n",
        "                      .format(wrong, w, word_freq.get(w, 0), right, word_freq.get(right, 0)))\n",
        "    dt = time.time() - start\n",
        "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
        "          .format(good / n, n, unknown / n, n / dt))\n",
        "    \n",
        "def Testset(lines):\n",
        "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
        "    return [(right, wrong)\n",
        "            for (right, wrongs) in (line.split(':') for line in lines)\n",
        "            for wrong in wrongs.split()]\n",
        "\n",
        "print(unit_tests())\n",
        "spelltest(Testset(open('spell-testset1.txt')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For bigram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unit_tests pass\n",
            "correction(contenpted) => contested (4); expected contented (13)\n",
            "correction(contende) => content (29); expected contented (13)\n",
            "correction(contended) => contended (9); expected contented (13)\n",
            "correction(contentid) => content (29); expected contented (13)\n",
            "correction(begining) => refining (1); expected beginning (143)\n",
            "correction(problam) => program (43); expected problem (71)\n",
            "correction(proble) => noble (48); expected problem (71)\n",
            "correction(proplen) => people (891); expected problem (71)\n",
            "correction(dirven) => dive (1); expected driven (66)\n",
            "correction(guic) => gulf (13); expected juice (5)\n",
            "correction(juce) => suck (3); expected juice (5)\n",
            "correction(juise) => jose (1); expected juice (5)\n",
            "correction(juse) => jose (1); expected juice (5)\n",
            "correction(localy) => lonely (13); expected locally (10)\n",
            "correction(compair) => complain (14); expected compare (29)\n",
            "correction(transportibility) => transportibility (0); expected transportability (0)\n",
            "correction(miniscule) => miniscule (0); expected minuscule (0)\n",
            "correction(aranged) => ranger (3); expected arranged (75)\n",
            "correction(poartry) => party (298); expected poetry (10)\n",
            "correction(poertry) => perry (5); expected poetry (10)\n",
            "correction(poetre) => pierre (1964); expected poetry (10)\n",
            "correction(poety) => booty (9); expected poetry (10)\n",
            "correction(powetry) => pottery (1); expected poetry (10)\n",
            "correction(leval) => devil (72); expected level (53)\n",
            "correction(unexpeted) => unexpended (1); expected unexpected (45)\n",
            "correction(stanerdizing) => stanerdizing (0); expected standardizing (0)\n",
            "correction(varable) => marble (10); expected variable (16)\n",
            "correction(futher) => other (1501); expected further (138)\n",
            "correction(seperate) => desperate (32); expected separate (69)\n",
            "correction(receit) => decent (9); expected receipt (13)\n",
            "correction(receite) => recent (53); expected receipt (13)\n",
            "correction(reciet) => rocket (5); expected receipt (13)\n",
            "correction(recipt) => resist (33); expected receipt (13)\n",
            "correction(remined) => reminder (6); expected remind (9)\n",
            "correction(inistals) => installs (1); expected initials (7)\n",
            "correction(initails) => installs (1); expected initials (7)\n",
            "correction(initals) => installs (1); expected initials (7)\n",
            "correction(intials) => indians (47); expected initials (7)\n",
            "correction(annt) => and (38312); expected aunt (52)\n",
            "correction(anut) => and (38312); expected aunt (52)\n",
            "correction(arnt) => and (38312); expected aunt (52)\n",
            "correction(intial) => intra (35); expected initial (18)\n",
            "correction(ther) => the (79809); expected there (2972)\n",
            "correction(biult) => but (5653); expected built (77)\n",
            "correction(totaly) => rotary (1); expected totally (9)\n",
            "correction(southen) => south (311); expected southern (194)\n",
            "correction(definately) => delicately (3); expected definitely (35)\n",
            "correction(fisited) => limited (79); expected visited (28)\n",
            "correction(viseted) => vested (21); expected visited (28)\n",
            "correction(vistid) => vista (2); expected visited (28)\n",
            "correction(vistied) => vested (21); expected visited (28)\n",
            "correction(ment) => kent (5); expected meant (113)\n",
            "correction(recieve) => relieve (20); expected receive (95)\n",
            "correction(sorces) => voices (149); expected sources (30)\n",
            "correction(wether) => other (1501); expected whether (357)\n",
            "correction(valuble) => value (106); expected valuable (33)\n",
            "correction(desicate) => delicate (54); expected desiccate (0)\n",
            "correction(dessicate) => delicate (54); expected desiccate (0)\n",
            "correction(dessiccate) => dessiccate (0); expected desiccate (0)\n",
            "correction(splended) => blended (5); expected splendid (77)\n",
            "correction(splended) => blended (5); expected splendid (77)\n",
            "correction(completly) => complete (144); expected completely (94)\n",
            "correction(acount) => about (1497); expected account (177)\n",
            "correction(semetary) => seminary (2); expected cemetery (2)\n",
            "correction(specal) => spell (9); expected special (157)\n",
            "correction(speical) => spinal (39); expected special (157)\n",
            "correction(lates) => wales (1); expected latest (17)\n",
            "correction(latets) => gates (34); expected latest (17)\n",
            "correction(latiest) => easiest (3); expected latest (17)\n",
            "correction(latist) => baptist (1); expected latest (17)\n",
            "correction(rember) => premier (2); expected remember (161)\n",
            "correction(remeber) => member (50); expected remember (161)\n",
            "correction(chaper) => cape (3); expected chapter (464)\n",
            "correction(chaphter) => chatter (8); expected chapter (464)\n",
            "correction(chaptur) => chatter (8); expected chapter (464)\n",
            "correction(cak) => a (21124); expected cake (6)\n",
            "correction(vairious) => vicious (18); expected various (155)\n",
            "correction(protend) => protest (19); expected pretend (8)\n",
            "correction(prtend) => intend (8); expected pretend (8)\n",
            "correction(chosing) => hoping (24); expected choosing (20)\n",
            "correction(rote) => more (1997); expected wrote (149)\n",
            "correction(wote) => more (1997); expected wrote (149)\n",
            "correction(awfall) => fall (124); expected awful (29)\n",
            "correction(afful) => foul (20); expected awful (29)\n",
            "correction(chalenges) => changes (163); expected challenges (2)\n",
            "correction(chalenges) => changes (163); expected challenges (2)\n",
            "correction(lugh) => luck (28); expected laugh (70)\n",
            "correction(ofen) => of (40024); expected often (443)\n",
            "correction(offen) => oven (7); expected often (443)\n",
            "correction(ofton) => onion (2); expected often (443)\n",
            "correction(somone) => some (1536); expected someone (160)\n",
            "correction(uneque) => cheque (2); expected unique (14)\n",
            "correction(diagrammaticaally) => diagrammaticaally (0); expected diagrammatically (0)\n",
            "correction(discription) => disruption (4); expected description (27)\n",
            "correction(poims) => coins (5); expected poems (3)\n",
            "correction(pomes) => home (294); expected poems (3)\n",
            "correction(perple) => temple (22); expected purple (29)\n",
            "correction(perpul) => peru (4); expected purple (29)\n",
            "correction(poarple) => parole (3); expected purple (29)\n",
            "correction(descide) => beside (218); expected decide (33)\n",
            "correction(articals) => arrivals (7); expected articles (86)\n",
            "correction(extented) => expected (126); expected extended (75)\n",
            "correction(hierachial) => hierachial (0); expected hierarchal (0)\n",
            "correction(realy) => relay (4); expected really (272)\n",
            "correction(relley) => relay (4); expected really (272)\n",
            "correction(relly) => relay (4); expected really (272)\n",
            "correction(voteing) => noting (10); expected voting (6)\n",
            "correction(wantid) => wanting (12); expected wanted (213)\n",
            "correction(wonted) => wonted (1); expected wanted (213)\n",
            "correction(defenitions) => definition (23); expected definitions (3)\n",
            "correction(levals) => evans (1); expected levels (1)\n",
            "correction(paralel) => parade (20); expected parallel (17)\n",
            "correction(paralell) => parallels (1); expected parallel (17)\n",
            "correction(parrallell) => parallels (1); expected parallel (17)\n",
            "correction(planed) => planed (1); expected planned (15)\n",
            "correction(transfred) => transfer (20); expected transferred (52)\n",
            "correction(muinets) => moines (1); expected minutes (146)\n",
            "correction(aranging) => branding (1); expected arrangeing (0)\n",
            "correction(accesing) => accusing (1); expected accessing (0)\n",
            "correction(stomac) => potomac (3); expected stomach (42)\n",
            "correction(stomec) => stones (13); expected stomach (42)\n",
            "correction(unfortunatly) => unfortunate (36); expected unfortunately (11)\n",
            "correction(acess) => races (8); expected access (56)\n",
            "correction(scarcly) => sharply (43); expected scarcely (65)\n",
            "correction(scarely) => safely (11); expected scarcely (65)\n",
            "correction(questionaire) => questionable (3); expected questionnaire (1)\n",
            "correction(refresment) => represent (16); expected refreshment (4)\n",
            "correction(embaras) => embargo (7); expected embarrass (0)\n",
            "correction(embarass) => embarass (0); expected embarrass (0)\n",
            "correction(vistors) => victory (131); expected visitors (69)\n",
            "correction(auxillary) => axillary (31); expected auxiliary (0)\n",
            "correction(descided) => decides (3); expected decided (149)\n",
            "correction(concider) => concise (4); expected consider (98)\n",
            "correction(failes) => wales (1); expected fails (20)\n",
            "correction(carrer) => carter (1); expected career (39)\n",
            "correction(cirtain) => britain (77); expected certain (361)\n",
            "correction(poame) => home (294); expected poem (6)\n",
            "correction(liew) => view (179); expected lieu (7)\n",
            "correction(lones) => jones (24); expected loans (13)\n",
            "correction(addresable) => addresable (0); expected addressable (0)\n",
            "correction(galery) => glory (49); expected gallery (11)\n",
            "correction(gallary) => galaxy (1); expected gallery (11)\n",
            "correction(gallrey) => alley (5); expected gallery (11)\n",
            "correction(centraly) => central (72); expected centrally (0)\n",
            "correction(familes) => smiles (18); expected families (45)\n",
            "correction(bycycle) => recycle (1); expected bicycle (1)\n",
            "correction(choise) => christ (32); expected choice (46)\n",
            "correction(oppesite) => appetite (12); expected opposite (80)\n",
            "correction(oppisit) => oppisit (0); expected opposite (80)\n",
            "correction(opposit) => oppose (14); expected opposite (80)\n",
            "correction(cartains) => curtain (22); expected curtains (5)\n",
            "correction(courtens) => counters (1); expected curtains (5)\n",
            "correction(curtans) => curtis (8); expected curtains (5)\n",
            "correction(curtians) => curtis (8); expected curtains (5)\n",
            "correction(curtions) => curtis (8); expected curtains (5)\n",
            "correction(adress) => arrest (58); expected address (76)\n",
            "correction(adres) => are (3630); expected address (76)\n",
            "correction(liason) => wilson (105); expected liaison (1)\n",
            "correction(superceed) => superseded (9); expected supersede (1)\n",
            "41% of 270 correct (6% unknown) at 13 words per second \n"
          ]
        }
      ],
      "source": [
        "def spelltest(tests, verbose=True):\n",
        "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
        "    import time\n",
        "    start = time.time()\n",
        "    good, unknown = 0, 0\n",
        "    n = len(tests)\n",
        "    for right, wrong in tests:\n",
        "        w = correct_text_bigram(wrong)\n",
        "        good += (w == right)\n",
        "        if w != right:\n",
        "            unknown += (right not in unique_words)\n",
        "            if verbose:\n",
        "                print('correction({}) => {} ({}); expected {} ({})'\n",
        "                      .format(wrong, w, word_freq.get(w, 0), right, word_freq.get(right, 0)))\n",
        "    dt = time.time() - start\n",
        "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
        "          .format(good / n, n, unknown / n, n / dt))\n",
        "    \n",
        "def Testset(lines):\n",
        "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
        "    return [(right, wrong)\n",
        "            for (right, wrongs) in (line.split(':') for line in lines)\n",
        "            for wrong in wrongs.split()]\n",
        "\n",
        "print(unit_tests())\n",
        "spelltest(Testset(open('spell-testset1.txt')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For bigram model with Laplase smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unit_tests pass\n",
            "correction(contende) => content (29); expected contented (13)\n",
            "correction(contended) => contended (9); expected contented (13)\n",
            "correction(contentid) => content (29); expected contented (13)\n",
            "correction(problam) => program (43); expected problem (71)\n",
            "correction(proble) => people (891); expected problem (71)\n",
            "correction(proplen) => people (891); expected problem (71)\n",
            "correction(dirven) => given (364); expected driven (66)\n",
            "correction(exstacy) => eustace (1); expected ecstasy (8)\n",
            "correction(guic) => music (56); expected juice (5)\n",
            "correction(juce) => such (1436); expected juice (5)\n",
            "correction(jucie) => judge (45); expected juice (5)\n",
            "correction(juise) => use (320); expected juice (5)\n",
            "correction(juse) => else (201); expected juice (5)\n",
            "correction(localy) => local (181); expected locally (10)\n",
            "correction(transportibility) => transportibility (0); expected transportability (0)\n",
            "correction(miniscule) => miniscule (0); expected minuscule (0)\n",
            "correction(aranged) => range (39); expected arranged (75)\n",
            "correction(poartry) => party (298); expected poetry (10)\n",
            "correction(poertry) => poverty (26); expected poetry (10)\n",
            "correction(poety) => post (114); expected poetry (10)\n",
            "correction(powetry) => power (545); expected poetry (10)\n",
            "correction(leval) => local (181); expected level (53)\n",
            "correction(stanerdizing) => stanerdizing (0); expected standardizing (0)\n",
            "correction(futher) => other (1501); expected further (138)\n",
            "correction(biscits) => visits (11); expected biscuits (8)\n",
            "correction(biscutes) => disputes (27); expected biscuits (8)\n",
            "correction(biscuts) => discuss (36); expected biscuits (8)\n",
            "correction(receit) => recent (53); expected receipt (13)\n",
            "correction(receite) => recent (53); expected receipt (13)\n",
            "correction(reciet) => recent (53); expected receipt (13)\n",
            "correction(recipt) => recent (53); expected receipt (13)\n",
            "correction(remine) => remove (53); expected remind (9)\n",
            "correction(remined) => defined (55); expected remind (9)\n",
            "correction(inetials) => initial (18); expected initials (7)\n",
            "correction(inistals) => install (1); expected initials (7)\n",
            "correction(initails) => initial (18); expected initials (7)\n",
            "correction(initals) => initial (18); expected initials (7)\n",
            "correction(intials) => initial (18); expected initials (7)\n",
            "correction(magnificant) => significant (39); expected magnificent (12)\n",
            "correction(annt) => and (38312); expected aunt (52)\n",
            "correction(anut) => and (38312); expected aunt (52)\n",
            "correction(arnt) => and (38312); expected aunt (52)\n",
            "correction(intial) => until (325); expected initial (18)\n",
            "correction(ther) => the (79809); expected there (2972)\n",
            "correction(biult) => but (5653); expected built (77)\n",
            "correction(totaly) => total (35); expected totally (9)\n",
            "correction(southen) => south (311); expected southern (194)\n",
            "correction(fisited) => limited (79); expected visited (28)\n",
            "correction(viseted) => listed (3); expected visited (28)\n",
            "correction(vistid) => visit (81); expected visited (28)\n",
            "correction(vistied) => listed (3); expected visited (28)\n",
            "correction(ment) => next (277); expected meant (113)\n",
            "correction(sorces) => source (94); expected sources (30)\n",
            "correction(wether) => other (1501); expected whether (357)\n",
            "correction(valuble) => value (106); expected valuable (33)\n",
            "correction(desicate) => designate (1); expected desiccate (0)\n",
            "correction(dessicate) => dedicate (1); expected desiccate (0)\n",
            "correction(dessiccate) => dessiccate (0); expected desiccate (0)\n",
            "correction(splened) => speed (31); expected splendid (77)\n",
            "correction(completly) => complete (144); expected completely (94)\n",
            "correction(acount) => about (1497); expected account (177)\n",
            "correction(lates) => last (565); expected latest (17)\n",
            "correction(latets) => rates (47); expected latest (17)\n",
            "correction(latist) => last (565); expected latest (17)\n",
            "correction(rember) => number (301); expected remember (161)\n",
            "correction(remeber) => member (50); expected remember (161)\n",
            "correction(chaper) => paper (177); expected chapter (464)\n",
            "correction(cak) => a (21124); expected cake (6)\n",
            "correction(pertend) => percent (1); expected pretend (8)\n",
            "correction(protend) => protein (4); expected pretend (8)\n",
            "correction(prtend) => friend (283); expected pretend (8)\n",
            "correction(pritend) => printed (27); expected pretend (8)\n",
            "correction(chosing) => housing (3); expected choosing (20)\n",
            "correction(rote) => more (1997); expected wrote (149)\n",
            "correction(wote) => more (1997); expected wrote (149)\n",
            "correction(awfall) => fall (124); expected awful (29)\n",
            "correction(chalenges) => changes (163); expected challenges (2)\n",
            "correction(chalenges) => changes (163); expected challenges (2)\n",
            "correction(lagh) => page (59); expected laugh (70)\n",
            "correction(lauf) => last (565); expected laugh (70)\n",
            "correction(laught) => light (277); expected laugh (70)\n",
            "correction(lugh) => such (1436); expected laugh (70)\n",
            "correction(ofen) => of (40024); expected often (443)\n",
            "correction(offen) => open (322); expected often (443)\n",
            "correction(somone) => some (1536); expected someone (160)\n",
            "correction(diagrammaticaally) => diagrammaticaally (0); expected diagrammatically (0)\n",
            "correction(poims) => point (223); expected poems (3)\n",
            "correction(pomes) => home (294); expected poems (3)\n",
            "correction(perple) => people (891); expected purple (29)\n",
            "correction(perpul) => peril (7); expected purple (29)\n",
            "correction(descide) => describe (51); expected decide (33)\n",
            "correction(extented) => expected (126); expected extended (75)\n",
            "correction(hierachial) => hierachial (0); expected hierarchal (0)\n",
            "correction(realy) => read (219); expected really (272)\n",
            "correction(relley) => reply (166); expected really (272)\n",
            "correction(relly) => well (1198); expected really (272)\n",
            "correction(voteing) => nothing (646); expected voting (6)\n",
            "correction(wantid) => want (323); expected wanted (213)\n",
            "correction(wonted) => wonted (1); expected wanted (213)\n",
            "correction(defenitions) => definition (23); expected definitions (3)\n",
            "correction(sissors) => sisters (16); expected scissors (19)\n",
            "correction(levals) => level (53); expected levels (1)\n",
            "correction(planed) => planed (1); expected planned (15)\n",
            "correction(transfred) => transfer (20); expected transferred (52)\n",
            "correction(muinets) => mines (22); expected minutes (146)\n",
            "correction(aranging) => changing (43); expected arrangeing (0)\n",
            "correction(accesing) => accepting (12); expected accessing (0)\n",
            "correction(stomac) => atomic (1); expected stomach (42)\n",
            "correction(stomec) => some (1536); expected stomach (42)\n",
            "correction(scarely) => surely (24); expected scarcely (65)\n",
            "correction(refresment) => represent (16); expected refreshment (4)\n",
            "correction(embaras) => embers (4); expected embarrass (0)\n",
            "correction(embarass) => embarass (0); expected embarrass (0)\n",
            "correction(vistors) => history (348); expected visitors (69)\n",
            "correction(auxillary) => axillary (31); expected auxiliary (0)\n",
            "correction(descided) => described (151); expected decided (149)\n",
            "correction(failes) => miles (110); expected fails (20)\n",
            "correction(carrer) => care (106); expected career (39)\n",
            "correction(poame) => home (294); expected poem (6)\n",
            "correction(liew) => view (179); expected lieu (7)\n",
            "correction(lones) => one (3371); expected loans (13)\n",
            "correction(addresable) => addresable (0); expected addressable (0)\n",
            "correction(centraly) => central (72); expected centrally (0)\n",
            "correction(familes) => miles (110); expected families (45)\n",
            "correction(bycycle) => cycle (1); expected bicycle (1)\n",
            "correction(choise) => those (1201); expected choice (46)\n",
            "correction(oppisit) => oppisit (0); expected opposite (80)\n",
            "correction(opposit) => deposit (24); expected opposite (80)\n",
            "correction(cartains) => certain (361); expected curtains (5)\n",
            "correction(certans) => certain (361); expected curtains (5)\n",
            "correction(courtens) => courses (9); expected curtains (5)\n",
            "correction(curtions) => portions (56); expected curtains (5)\n",
            "correction(adress) => access (56); expected address (76)\n",
            "correction(adres) => are (3630); expected address (76)\n",
            "correction(liaision) => division (110); expected liaison (1)\n",
            "correction(liason) => reason (191); expected liaison (1)\n",
            "correction(inconvient) => convient (1); expected inconvenient (4)\n",
            "correction(superceed) => supervened (1); expected supersede (1)\n",
            "49% of 270 correct (6% unknown) at 20 words per second \n"
          ]
        }
      ],
      "source": [
        "def spelltest(tests, verbose=True):\n",
        "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
        "    import time\n",
        "    start = time.time()\n",
        "    good, unknown = 0, 0\n",
        "    n = len(tests)\n",
        "    for right, wrong in tests:\n",
        "        w = correct_text_bigram_with_laplase_smoothing(wrong)\n",
        "        good += (w == right)\n",
        "        if w != right:\n",
        "            unknown += (right not in unique_words)\n",
        "            if verbose:\n",
        "                print('correction({}) => {} ({}); expected {} ({})'\n",
        "                      .format(wrong, w, word_freq.get(w, 0), right, word_freq.get(right, 0)))\n",
        "    dt = time.time() - start\n",
        "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\n",
        "          .format(good / n, n, unknown / n, n / dt))\n",
        "    \n",
        "def Testset(lines):\n",
        "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
        "    return [(right, wrong)\n",
        "            for (right, wrongs) in (line.split(':') for line in lines)\n",
        "            for wrong in wrongs.split()]\n",
        "\n",
        "print(unit_tests())\n",
        "spelltest(Testset(open('spell-testset1.txt')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_errors(correct_text, error_rate = 0.2):\n",
        "    found_words = list(re.finditer(r'\\b\\w+\\b', correct_text))\n",
        "    corrupted_text = []\n",
        "    cur_idx = 0\n",
        "\n",
        "    num_of_errors = int(len(found_words) * error_rate)\n",
        "    error_indices = random.sample(range(len(found_words)), num_of_errors)\n",
        "\n",
        "    for idx, match in enumerate(found_words):\n",
        "        word = match.group()\n",
        "        start, end = match.span()\n",
        "\n",
        "        # append the text before the word ro save spaces and punctuation\n",
        "        corrupted_text.append(correct_text[cur_idx:start])\n",
        "\n",
        "        # randomly add errors\n",
        "        if idx in error_indices and len(word) > 1:\n",
        "            error_type = random.choice([\"add\", \"delete\", \"replace\", \"swap\"])\n",
        "            if error_type == \"add\":\n",
        "                corrupted_word = random.choice(add_char(word))\n",
        "            elif error_type == \"delete\":\n",
        "                corrupted_word = random.choice(delete_char(word)) if len(word) > 2 else word\n",
        "            elif error_type == \"replace\":\n",
        "                corrupted_word = random.choice(replace_char(word))\n",
        "            elif error_type == \"swap\":\n",
        "                corrupted_word = random.choice(swap_chars(word))\n",
        "        else:\n",
        "            corrupted_word = word \n",
        "\n",
        "        corrupted_text.append(corrupted_word)\n",
        "\n",
        "        cur_idx = end\n",
        "\n",
        "    # save the remaining puntuation and spaces that are not words\n",
        "    corrupted_text.append(correct_text[cur_idx:])\n",
        "\n",
        "    return \"\".join(corrupted_text), num_of_errors\n",
        "\n",
        "# function to calculate the model accuracy as the (number of correctly corrected words) / (number of all words with errors that are present in the corpus)\n",
        "def calculate_word_accuracy(original, corrupted, corrected):\n",
        "    initial_words = re.findall(r'\\b\\w+\\b', original)\n",
        "    words_with_errors = re.findall(r'\\b\\w+\\b', corrupted)\n",
        "    corrected_words = re.findall(r'\\b\\w+\\b', corrected)\n",
        "    correctly_corrected_words_count = 0\n",
        "    possible_corrected_words = 0\n",
        "\n",
        "    for initial_word, word_with_error, corrected_word in zip(initial_words, words_with_errors, corrected_words):\n",
        "        if initial_word in unique_words:\n",
        "            possible_corrected_words+=1\n",
        "            if initial_word == corrected_word and initial_word != word_with_error:\n",
        "                correctly_corrected_words_count+=1\n",
        "    \n",
        "    if possible_corrected_words == 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return correctly_corrected_words_count / possible_corrected_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test sentence "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram accuracy: 0.25\n",
            "Bigram accuracy: 0.25\n",
            "Bigram with Laplase smoothing accuracy: 0.25\n"
          ]
        }
      ],
      "source": [
        "test_sentence_1 = \"The autumn season brought colorful leaves as artists prepared for an annual exhibition showcasing contemporary artwork.\"\n",
        "test_sentence_1_with_errors = \"The hutumn season brought colorful leaves as artists prepared for an sannual exhibition showcasing conetmporary artwork.\"\n",
        "\n",
        "corrected_unigram = correct_text(test_sentence_1_with_errors)\n",
        "corrected_bigram = correct_text_bigram(test_sentence_1_with_errors)\n",
        "corrected_bigram_laplase_smoothing = correct_text_bigram_with_laplase_smoothing(test_sentence_1_with_errors)\n",
        "\n",
        "print(\"Unigram accuracy:\", calculate_word_accuracy(test_sentence_1, test_sentence_1_with_errors, corrected_unigram))\n",
        "print(\"Bigram accuracy:\", calculate_word_accuracy(test_sentence_1, test_sentence_1_with_errors, corrected_bigram))\n",
        "print(\"Bigram with Laplase smoothing accuracy:\", calculate_word_accuracy(test_sentence_1, test_sentence_1_with_errors, corrected_bigram_laplase_smoothing))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram accuracy: 0.08695652173913043\n",
            "Bigram accuracy: 0.13043478260869565\n",
            "Bigram with Laplase smoothing accuracy: 0.11594202898550725\n"
          ]
        }
      ],
      "source": [
        "test_paragraph = \"\"\"As the sun set, an art exhibition opened in the city's cultural center, showcasing contemporary artwork from renowned \n",
        "and emerging visual artists. The gallery was filled with vibrant paintings, abstract sculptures, and multimedia installations that explored \n",
        "themes of identity and transformation. Art enthusiasts and collectors engaged in thoughtful discussions about the impact of modern art on society. \n",
        "Meanwhile, the event organizers prepared for an evening panel featuring well-known creative professionals discussing the future of digital media \n",
        "in the artistic landscape.\"\"\"\n",
        "\n",
        "# added some mistakes using add_errors function. To reproduce results I fixed the paragraph.\n",
        "test_paragraph_with_errors = \"\"\"As the sun set, an art exhisbition opened in the ity's cultural cehnter, showcasing contemporary artwork from renowned \n",
        "and emergin visual artists. The gallery was flilled with vibrakt paintings, abstract sculptures, and multimedia installations taht explored \n",
        "themes fo identity and transformation. Art enthusiasts and collectors engaged in thoughtful discussions about the impact of modern art fn societjy. \n",
        "Meanwhile, th event orgainzers prepared ofr an evening panel featuring well-known creative professionals discussign the future zof digital media \n",
        "in th artistic landscape.\"\"\"\n",
        "\n",
        "corrected_paragraph_unigram = correct_text(test_paragraph_with_errors)\n",
        "corrected_paragraph_bigram = correct_text_bigram(test_paragraph_with_errors)\n",
        "corrected_paragraph_bigram_with_laplase_smoothing = correct_text_bigram_with_laplase_smoothing(test_paragraph_with_errors)\n",
        "\n",
        "unigram_accuracy = calculate_word_accuracy(test_paragraph, test_paragraph_with_errors, corrected_paragraph_unigram)\n",
        "bigram_accuracy = calculate_word_accuracy(test_paragraph, test_paragraph_with_errors, corrected_paragraph_bigram)\n",
        "bigram_accuracy_with_laplase_smoothing = calculate_word_accuracy(test_paragraph, test_paragraph_with_errors, corrected_paragraph_bigram_with_laplase_smoothing)\n",
        "\n",
        "print(f\"Unigram accuracy: {unigram_accuracy}\")\n",
        "print(f\"Bigram accuracy: {bigram_accuracy}\")\n",
        "print(f\"Bigram with Laplase smoothing accuracy: {bigram_accuracy_with_laplase_smoothing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the fragment from the book \"The Lord of The Rings\" by John Ronald Reuel Tolkien"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unigram accuracy: 0.11504424778761062\n",
            "Bigram accuracy: 0.13274336283185842\n",
            "Bigram with Laplase smoothing accuracy: 0.1415929203539823\n"
          ]
        }
      ],
      "source": [
        "# text fragment from \"The Lord of The Rings\"\n",
        "test_text = \"This tale grew in the telling, until it became a history of the Great War of the Ring and included many glimpses of the yet more ancient history that preceded it. It was begun soon after The Hobbit was written and before its publication in 1937; but I did not go on with this sequel, for I wished first to complete and set in order the myth- ology and legends of the Elder Days, which had then been taking shape for some years. I desired to do this for my own satisfaction, and I had little hope that other people would be interested in this work, especially since it was primarily linguistic in inspiration and was begun in order to provide the necessary background of ‘history’ for Elvish tongues.\"\n",
        "# test_text_with_errors, added_error_num = add_errors(test_text)\n",
        "test_text_with_errors = \"\"\"This tle grew in the telling, unti it becwme a history of the Great War of lthe Ring and included many glimpses of the yet more ancient history thft preceded ti. It was bmgun soon after The Hobbit was written and before its publication in 1937; bt I did not go on with this seqel, fro I wished first to complete annd set in order thd myth- ology and legends of the Elder iDays, whijch had hen been making shape for some yeras. I desired to do ths for my own satisfaction, and I had little hope that other speople would be interested in this work, especially since it was primarily linguistic in inspiration nnd was begun in oredr to provide the necessary background of ‘histojry’ fvr Elvish tongues.\"\"\"\n",
        "\n",
        "\n",
        "corrected_unigram = correct_text(test_text_with_errors)\n",
        "corrected_bigram = correct_text_bigram(test_text_with_errors)\n",
        "corrected_bigram_with_laplase_smoothing = correct_text_bigram_with_laplase_smoothing(test_text_with_errors)\n",
        "# correct_with_beam_search = correct_text_bigram_beam_search(test_text_with_errors, 3)\n",
        "print(\"Unigram accuracy:\", calculate_word_accuracy(test_text, test_text_with_errors, corrected_unigram))\n",
        "print(\"Bigram accuracy:\", calculate_word_accuracy(test_text, test_text_with_errors, corrected_bigram))\n",
        "print(\"Bigram with Laplase smoothing accuracy:\", calculate_word_accuracy(test_text, test_text_with_errors, corrected_bigram_with_laplase_smoothing))\n",
        "# print(\"Beam search accuracy:\", calculate_word_accuracy(test_text, test_text_with_errors, correct_with_beam_search))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation results\n",
        "\n",
        "I decided to test the implemented models on 5 test cases.\n",
        "\n",
        "✏️ **without context** (to test the model ability of correcting single words)\n",
        "\n",
        "1. Norvig's unit tests\n",
        "2. Words from file `spell-testset1.txt`\n",
        "\n",
        "📝 **with context** (to test the model ability to capture the context)\n",
        "\n",
        "3. Sentence created from the bigrams listed in `count_2w.txt`.\n",
        "4. Paragraph created from the bigrams listed in `count_2w.txt`.\n",
        "5. Fragment from the book \"The Lord of The Rings\".\n",
        "\n",
        "The errors to the context test cases were added using function `add_errors()` that randomly addes mistakes to the correct words with the given error frequency.\n",
        "\n",
        "### Results\n",
        "\n",
        "I calculated the model accuracy as the (number of correctly corrected words)/(the number of words that had errors and were present in the corpus).\n",
        "\n",
        "| Test case                  | Unigram | Simple bigram | Bigram with Laplase smoothing |\n",
        "|------------------------------------|---------|---------|---------|\n",
        "| Norvig's unit tests               | passed  | passed  | passed   |\n",
        "| Words test file (`spell-testset1.txt` without context) | 74%     | 41%     | 49%     |\n",
        "| Accuracy on test sentence         | 0.25    | 0.25    | 0.25     |\n",
        "| Accuracy on the test paragraph    | 0.087    | 0.13    | 0.116   |\n",
        "| Accuracy on \"The Lord of The Rings\" fragment | 0.115   | 0.133   | 0.142   |\n",
        "\n",
        "The original Norwig's solution reached 75% on the words from `spell-testset1.txt` while my implementation achieves 74%. I think that these results are really close and this could happen because as I mentioned before in my case `big.txt` dataset was slightly larger.\n",
        "\n",
        "From the obtained results we can see that bigram models performed worse than the unigram model on single word test cases. Nevertheless, in the test cases with the context bigram models performed better and the accuracy was higher for the bigram model with Laplase smoothing 😊\n",
        "\n",
        "\n",
        "## Future work\n",
        "1. Keyboard layout: correct probabilities of candidates based on their location on the keyboard.\n",
        "2. Use characters changing frequencies\n",
        "\n",
        "In the website with Norvig model I found the file `count_1edit.txt` with the mispelling frequency of the given characters.\n",
        "\n",
        "4. Pay attention to punctuation.\n",
        "\n",
        "I believe that if we include punctuation into N-grams, the results of the model will improve because some words are more likely to occur at the beginning of a sentence, some at the end, and conjunctions after commas\n",
        "\n",
        "5. Use beam search\n",
        "\n",
        "In the current solution, the model always chooses the word with the highest probability, but it is possible that the word with a lower probability is more appropriate at the moment, and further correction of the text will result in a higher final probability.\n",
        "\n",
        "## Lessons learned\n",
        "- develop more maintainable code that can be simply reused\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Useful resources (also included in the archive in moodle):\n",
        "\n",
        "1. [Possible dataset with N-grams](https://www.ngrams.info/download_coca.asp)\n",
        "2. [Damerau–Levenshtein distance](https://en.wikipedia.org/wiki/Damerau–Levenshtein_distance#:~:text=Informally%2C%20the%20Damerau–Levenshtein%20distance,one%20word%20into%20the%20other.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
